{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea8b7ed",
   "metadata": {
    "id": "bea8b7ed"
   },
   "source": [
    "# Active Learning for Text Classification using Small-Text\n",
    "*Notebook 1*  \n",
    "This is an introductory example that shows you how to use [small-text](https://github.com/webis-de/small-text) to perform active learning for text classification using state-of-the-art transformer models.\n",
    "\n",
    "----\n",
    "\n",
    "## Overview\n",
    "\n",
    "- [Part I: Installation](#nb1-part1-installation)\n",
    "- [Part II: Data](#nb1-part2-data)\n",
    "- [Part III: Setting up the Active Learner](#nb1-part3-active-learning)\n",
    "- [Part IV: Plotting the Results](#nb1-part4-plotting)\n",
    "\n",
    "----\n",
    "\n",
    "<a id=\"nb1-part1-installation\"></a>\n",
    "## I. Installation\n",
    "\n",
    "First, we install small-text for its active learning functionality, [datasets](https://github.com/huggingface/datasets) to load an example dataset, and [matptlotlib](https://matplotlib.org/) to plot the learning curves at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837556c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:05.196088Z",
     "iopub.status.busy": "2025-06-05T03:19:05.195441Z",
     "iopub.status.idle": "2025-06-05T03:19:05.216320Z",
     "shell.execute_reply": "2025-06-05T03:19:05.214030Z",
     "shell.execute_reply.started": "2025-06-05T03:19:05.196037Z"
    },
    "id": "837556c3",
    "outputId": "1f1a28d4-4261-4d1a-8a85-309e6adc621b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set tmp directory while trying for convenient clean up\n",
    "import os \n",
    "TMP_DIR_VARIABLE = 'active_patcher_TEMP'\n",
    "tmp_dir = '/root/active-patcher/tmp'\n",
    "os.environ[TMP_DIR_VARIABLE] = tmp_dir\n",
    "# automatically create tmp_dir\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.mkdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cddec",
   "metadata": {
    "id": "658cddec"
   },
   "source": [
    "### Preparation\n",
    "\n",
    "You can skip this part when reading for the first time if you are only interested in active learning. Here, we configure the loggging behavior and display progress bars display of the `datasets` library to improve its appearance in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13170d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:05.220706Z",
     "iopub.status.busy": "2025-06-05T03:19:05.220361Z",
     "iopub.status.idle": "2025-06-05T03:19:06.817203Z",
     "shell.execute_reply": "2025-06-05T03:19:06.815997Z",
     "shell.execute_reply.started": "2025-06-05T03:19:05.220668Z"
    },
    "id": "13170d96",
    "outputId": "f8e77f78-5616-4282-db40-c2ef4e63336b"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# disables the progress bar for notebooks: https://github.com/huggingface/datasets/issues/2651\n",
    "datasets.logging.get_verbosity = lambda: logging.NOTSET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35a787",
   "metadata": {
    "id": "1c35a787"
   },
   "source": [
    "Moreover, we update the default matplotlib settings to receive a more visually appealing plot at the end of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269ce876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:06.818925Z",
     "iopub.status.busy": "2025-06-05T03:19:06.818482Z",
     "iopub.status.idle": "2025-06-05T03:19:06.971545Z",
     "shell.execute_reply": "2025-06-05T03:19:06.970405Z",
     "shell.execute_reply.started": "2025-06-05T03:19:06.818892Z"
    },
    "id": "269ce876"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({'xtick.labelsize': 14, 'ytick.labelsize': 14, 'axes.labelsize': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d6d3f",
   "metadata": {
    "id": "741d6d3f"
   },
   "source": [
    "Finally, we will fix the random seeds so that readers do not get confused when the results change upon repeated execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7be9231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:06.973297Z",
     "iopub.status.busy": "2025-06-05T03:19:06.972778Z",
     "iopub.status.idle": "2025-06-05T03:19:09.001987Z",
     "shell.execute_reply": "2025-06-05T03:19:09.000744Z",
     "shell.execute_reply.started": "2025-06-05T03:19:06.973265Z"
    },
    "id": "e7be9231"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5fd19",
   "metadata": {
    "id": "bdf5fd19"
   },
   "source": [
    "<a id=\"nb1-part2-data\"></a>\n",
    "## II. Data\n",
    "\n",
    "First, we load the rotten tomatoes dataset. This dataset contains movie reviews sentences, which are labeled by their sentiment as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1b4e73-73be-494f-933b-0edcec905836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:09.005387Z",
     "iopub.status.busy": "2025-06-05T03:19:09.004189Z",
     "iopub.status.idle": "2025-06-05T03:19:13.805142Z",
     "shell.execute_reply": "2025-06-05T03:19:13.803869Z",
     "shell.execute_reply.started": "2025-06-05T03:19:09.005305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>diff</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://github.com/omniauth/omniauth/commit/108f054837735a31430fca4b75a623f5d447375b</th>\n",
       "      <td>Update tested ruby versions</td>\n",
       "      <td>diff --git a/README.md b/README.md\\nindex 4a2f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/omniauth/omniauth/commit/f654faf709bbb3871b7fc7228aa481a5f96952e5</th>\n",
       "      <td>Remove 2_0-indev from CI tracking</td>\n",
       "      <td>diff --git a/.github/workflows/main.yml b/.git...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/h2o/h2o/commit/fbe835bf031f0ffef6b9844bcc2bbb71dce56478</th>\n",
       "      <td>[h2olog] Fix parameter position in example usa...</td>\n",
       "      <td>diff --git a/src/h2olog/h2olog.cc b/src/h2olog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/h2o/h2o/commit/b414dcf5bdc3477432d0c65abd3b8a1e736c94e1</th>\n",
       "      <td>ci: fix a regression that step scripts should ...</td>\n",
       "      <td>diff --git a/.github/workflows/ci.yml b/.githu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/heimdal/heimdal/commit/936d8dd4ee944fce67f4645fc857937da4ea21df</th>\n",
       "      <td>asn1: Add SRVName to PKIX module\\n\\nThis is in...</td>\n",
       "      <td>diff --git a/lib/asn1/rfc2459.asn1 b/lib/asn1/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/josh/rails/commit/605aadb3cdba9f469e88c39c0cad7448d59a9f0c</th>\n",
       "      <td>protect new rails apps from csrf by default.\\n...</td>\n",
       "      <td>diff --git a/railties/helpers/application.rb b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/cakephp/cakephp/commit/69e5226fd2b3a9f6386527ef00159a03c53bbf0c</th>\n",
       "      <td>Merge pull request #7021 from quickapps/master...</td>\n",
       "      <td>diff --git a/src/Network/Response.php b/src/Ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/php/php-src/commit/80367584910885baa1a2a4476a4a31efdcf0c9c0</th>\n",
       "      <td>Fix bug #69646\\tOS command injection vulnerabi...</td>\n",
       "      <td>diff --git a/ext/standard/exec.c b/ext/standar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/cakephp/cakephp/commit/92e3e09fdc218ebf8eb50e896dcb1728d02eadfc</th>\n",
       "      <td>Fix directory traversal security checking\\n\\nf...</td>\n",
       "      <td>diff --git a/src/Network/Response.php b/src/Ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://github.com/MISP/MISP/commit/9eb5b7ffb7a5fc8f8fe8c0fe40f070dd92d05b6f</th>\n",
       "      <td>Fixed vulnerability\\n\\n- Persistent XSS throug...</td>\n",
       "      <td>diff --git a/app/View/Threads/view.ctp b/app/V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              message  \\\n",
       "github                                                                                                  \n",
       "https://github.com/omniauth/omniauth/commit/108...                        Update tested ruby versions   \n",
       "https://github.com/omniauth/omniauth/commit/f65...                  Remove 2_0-indev from CI tracking   \n",
       "https://github.com/h2o/h2o/commit/fbe835bf031f0...  [h2olog] Fix parameter position in example usa...   \n",
       "https://github.com/h2o/h2o/commit/b414dcf5bdc34...  ci: fix a regression that step scripts should ...   \n",
       "https://github.com/heimdal/heimdal/commit/936d8...  asn1: Add SRVName to PKIX module\\n\\nThis is in...   \n",
       "...                                                                                               ...   \n",
       "https://github.com/josh/rails/commit/605aadb3cd...  protect new rails apps from csrf by default.\\n...   \n",
       "https://github.com/cakephp/cakephp/commit/69e52...  Merge pull request #7021 from quickapps/master...   \n",
       "https://github.com/php/php-src/commit/803675849...  Fix bug #69646\\tOS command injection vulnerabi...   \n",
       "https://github.com/cakephp/cakephp/commit/92e3e...  Fix directory traversal security checking\\n\\nf...   \n",
       "https://github.com/MISP/MISP/commit/9eb5b7ffb7a...  Fixed vulnerability\\n\\n- Persistent XSS throug...   \n",
       "\n",
       "                                                                                                 diff  \\\n",
       "github                                                                                                  \n",
       "https://github.com/omniauth/omniauth/commit/108...  diff --git a/README.md b/README.md\\nindex 4a2f...   \n",
       "https://github.com/omniauth/omniauth/commit/f65...  diff --git a/.github/workflows/main.yml b/.git...   \n",
       "https://github.com/h2o/h2o/commit/fbe835bf031f0...  diff --git a/src/h2olog/h2olog.cc b/src/h2olog...   \n",
       "https://github.com/h2o/h2o/commit/b414dcf5bdc34...  diff --git a/.github/workflows/ci.yml b/.githu...   \n",
       "https://github.com/heimdal/heimdal/commit/936d8...  diff --git a/lib/asn1/rfc2459.asn1 b/lib/asn1/...   \n",
       "...                                                                                               ...   \n",
       "https://github.com/josh/rails/commit/605aadb3cd...  diff --git a/railties/helpers/application.rb b...   \n",
       "https://github.com/cakephp/cakephp/commit/69e52...  diff --git a/src/Network/Response.php b/src/Ne...   \n",
       "https://github.com/php/php-src/commit/803675849...  diff --git a/ext/standard/exec.c b/ext/standar...   \n",
       "https://github.com/cakephp/cakephp/commit/92e3e...  diff --git a/src/Network/Response.php b/src/Ne...   \n",
       "https://github.com/MISP/MISP/commit/9eb5b7ffb7a...  diff --git a/app/View/Threads/view.ctp b/app/V...   \n",
       "\n",
       "                                                    label  \n",
       "github                                                     \n",
       "https://github.com/omniauth/omniauth/commit/108...      0  \n",
       "https://github.com/omniauth/omniauth/commit/f65...      0  \n",
       "https://github.com/h2o/h2o/commit/fbe835bf031f0...      0  \n",
       "https://github.com/h2o/h2o/commit/b414dcf5bdc34...      0  \n",
       "https://github.com/heimdal/heimdal/commit/936d8...      0  \n",
       "...                                                   ...  \n",
       "https://github.com/josh/rails/commit/605aadb3cd...      1  \n",
       "https://github.com/cakephp/cakephp/commit/69e52...      1  \n",
       "https://github.com/php/php-src/commit/803675849...      1  \n",
       "https://github.com/cakephp/cakephp/commit/92e3e...      1  \n",
       "https://github.com/MISP/MISP/commit/9eb5b7ffb7a...      1  \n",
       "\n",
       "[1147 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = pd.read_csv(r'./datasets/negative+CC-900repos.csv',encoding='utf_8_sig')\n",
    "neg['label'] = 0\n",
    "pos = pd.read_csv(r'./datasets/positive+CC-900repos.csv', encoding='utf_8_sig')\n",
    "pos['label'] = 1\n",
    "df = pd.concat([neg[['github','message','diff','label']],pos[['github','message','diff','label']]],axis=0,ignore_index=False).set_index('github')\n",
    "df.fillna('', inplace=True)\n",
    "# 1是100%的意思\n",
    "# shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df =  df[df['diff'].str.len()<512]\n",
    "label2id={'negative':0,'positive':1}\n",
    "df = df.replace({\"label\": label2id})\n",
    "df = df.rename(columns={\"github\":'id'})\n",
    "# X_labeled_full = df.sample(100)\n",
    "# df['project_name'] = df['github'].str.extract(r'github\\.com/([^/]+)')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7ede47-af4d-453a-8225-ad6f6f91f7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:13.807163Z",
     "iopub.status.busy": "2025-06-05T03:19:13.806632Z",
     "iopub.status.idle": "2025-06-05T03:19:13.817272Z",
     "shell.execute_reply": "2025-06-05T03:19:13.816108Z",
     "shell.execute_reply.started": "2025-06-05T03:19:13.807121Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754e5b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:13.821207Z",
     "iopub.status.busy": "2025-06-05T03:19:13.820793Z",
     "iopub.status.idle": "2025-06-05T03:19:13.874489Z",
     "shell.execute_reply": "2025-06-05T03:19:13.873373Z",
     "shell.execute_reply.started": "2025-06-05T03:19:13.821171Z"
    },
    "id": "754e5b56",
    "outputId": "b0aa5fd9-5f43-4b7d-c6b3-c754c51dafc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training samples:\n",
      "\n",
      "0   diff --git a/index.php b/index.php\n",
      "index 1d2db34..cb39173 100644\n",
      "--- a/index.php\n",
      "+++ b/index.php\n",
      "@@ -464,6 +464,7 @@\n",
      "         if (count === 0) {\n",
      "             $(\".list-group\").prepend(\"<li class=\\\"list-group-item\\\" id=\\\"search-error\\\">No tasks found</li>\");\n",
      "         }\n",
      "+        document.title = \"Burden (\" + count + \")\";\n",
      "     });\n",
      "     /* End */\n",
      "     /* Set Up Notifications */\n",
      "\n",
      "0   diff --git a/.zuul.yaml b/.zuul.yaml\n",
      "index 3a545311..d201b5c9 100644\n",
      "--- a/.zuul.yaml\n",
      "+++ b/.zuul.yaml\n",
      "@@ -10,7 +10,6 @@\n",
      "       - openstack/heat-templates\n",
      " \n",
      " - project:\n",
      "-    name: openstack/heat-templates\n",
      "     check:\n",
      "       jobs:\n",
      "         - heat-templates-check\n",
      "\n",
      "0   diff --git a/.gitignore b/.gitignore\n",
      "new file mode 100644\n",
      "index 0000000..eda3292\n",
      "--- /dev/null\n",
      "+++ b/.gitignore\n",
      "@@ -0,0 +1,8 @@\n",
      "+# Ignore Saurus site specific files\n",
      "+config.php\n",
      "+error.log\n",
      "+classes/smarty/templates/\n",
      "+classes/smarty/templates_c/\n",
      "+public/\n",
      "+shared/\n",
      "+.htaccess\n",
      "\n",
      "0   diff --git a/engine/Monstra.php b/engine/Monstra.php\n",
      "index 3f26cc81..b1a50fb7 100644\n",
      "--- a/engine/Monstra.php\n",
      "+++ b/engine/Monstra.php\n",
      "@@ -31,7 +31,7 @@ class Monstra\n",
      "     /**\n",
      "      * The version of Monstra\n",
      "      */\n",
      "-    const VERSION = '3.0.3';\n",
      "+    const VERSION = '3.0.4';\n",
      " \n",
      " \n",
      "     /**\n",
      "\n",
      "0   diff --git a/.github/workflows/scan.yml b/.github/workflows/scan.yml\n",
      "index f8e54a1..ec6ba52 100644\n",
      "--- a/.github/workflows/scan.yml\n",
      "+++ b/.github/workflows/scan.yml\n",
      "@@ -1,6 +1,10 @@\n",
      " name: static code analysis\n",
      " \n",
      "-on: [push]\n",
      "+on:\n",
      "+  push:\n",
      "+  schedule:\n",
      "+    - cron: '0 0 * * 1'\n",
      "+\n",
      " env:\n",
      "   SCAN_IMG:\n",
      "     yes-docker-local.artifactory.in.yubico.org/static-code-analysis/c:v1\n",
      "\n",
      "0   diff --git a/share/templates/user/email/edit.tmpl b/share/templates/user/email/edit.tmpl\n",
      "index a1f8418..a37633d 100644\n",
      "--- a/share/templates/user/email/edit.tmpl\n",
      "+++ b/share/templates/user/email/edit.tmpl\n",
      "@@ -69,7 +69,7 @@ Unverified\n",
      " \t\t<ul>\n",
      " \t\t\t<li>\n",
      " \t\t\t\t<input type=\"hidden\" name=\"action\" value=\"remove\" />\n",
      "-\t\t\t\t<input id=\"button\" type=\"submit\" name=\"button\" value=\"Reomve Email\" />\n",
      "+\t\t\t\t<input id=\"button\" type=\"submit\" name=\"button\" value=\"Remove Email\" />\n",
      " \t\t\t</li>\n",
      " \t\t</ul>\n",
      " \t</fieldset>\n",
      "\n",
      "0   diff --git a/testsuite/requirements.txt b/testsuite/requirements.txt\n",
      "index 80ba8e067..665ed961d 100644\n",
      "--- a/testsuite/requirements.txt\n",
      "+++ b/testsuite/requirements.txt\n",
      "@@ -7,4 +7,4 @@ nose\n",
      " mock\n",
      " pylint<0.29\n",
      " pep8\n",
      "-sphinx<1.5\n",
      "+sphinx\n",
      "\n",
      "0   diff --git a/oc/classes/image.php b/oc/classes/image.php\n",
      "index 2f4e3bf2f..3c4009b17 100755\n",
      "--- a/oc/classes/image.php\n",
      "+++ b/oc/classes/image.php\n",
      "@@ -54,7 +54,7 @@ public function orientate()\n",
      "                 break;\n",
      " \n",
      "                 case 6:\n",
      "-                    $rotate = 180;\n",
      "+                    $rotate = 0;\n",
      "                     $flip = FALSE;\n",
      "                 break;\n",
      " \n",
      "\n",
      "0   diff --git a/lib/ytnef.c b/lib/ytnef.c\n",
      "index 6c79004..45ecb23 100644\n",
      "--- a/lib/ytnef.c\n",
      "+++ b/lib/ytnef.c\n",
      "@@ -1180,7 +1180,7 @@ int TNEFParse(TNEFStruct *TNEF) {\n",
      "       printf(\"ERROR: Field with size of 0\\n\");\n",
      "       return YTNEF_ERROR_READING_DATA;\n",
      "     }\n",
      "-    PREALLOCCHECK(size, 1000000);\n",
      "+    PREALLOCCHECK(size, 50*1024*1024);\n",
      "     data = calloc(size, sizeof(BYTE));\n",
      "     ALLOCCHECK(data);\n",
      "     if (TNEFRawRead(TNEF, data, size, &header_checksum) < 0) {\n",
      "\n",
      "0   diff --git a/src/dist-static/RELEASE_NOTES-c3p0-0.9.5 b/src/dist-static/RELEASE_NOTES-c3p0-0.9.5\n",
      "index 4b934b21..d3171bdf 100644\n",
      "--- a/src/dist-static/RELEASE_NOTES-c3p0-0.9.5\n",
      "+++ b/src/dist-static/RELEASE_NOTES-c3p0-0.9.5\n",
      "@@ -1,7 +1,7 @@\n",
      " RELEASE NOTES, c3p0-0.9.5\n",
      " =========================\n",
      " \n",
      "-+ Full JDBC4 support, builds under current JDKs. Yay!\n",
      "++ Full JDBC4 support.\n",
      " \n",
      " + Support for logging the SLF4J / logback library\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "# 构造 DatasetDict\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'test': Dataset.from_pandas(val_df)\n",
    "})\n",
    "\n",
    "# num_classes = raw_dataset['train'].features['label'].num_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('First 10 training samples:\\n')\n",
    "for i in range(10):\n",
    "    print(raw_dataset['train']['label'][i], ' ', raw_dataset['train']['diff'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742f7d7",
   "metadata": {
    "id": "1742f7d7"
   },
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Next, we have to convert this raw text data into a format usable by small-text. Since the transformer-based classification in small-text uses huggingface transformers this step is pretty similar to the preprocessing you may know from transformers, with the addition that the end result must be a `TransformersDataset`. In this example, we use `bert-base-uncased` as transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c52f326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:13.876144Z",
     "iopub.status.busy": "2025-06-05T03:19:13.875817Z",
     "iopub.status.idle": "2025-06-05T03:19:14.162779Z",
     "shell.execute_reply": "2025-06-05T03:19:14.161592Z",
     "shell.execute_reply.started": "2025-06-05T03:19:13.876109Z"
    },
    "id": "2c52f326"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_model_name = './models/codebert-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    transformer_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252a546",
   "metadata": {
    "id": "3252a546"
   },
   "source": [
    "We use the `TransformersDataset.from_arrays()` helper function which constructs a `TransformersDataset` instance using the tokenizer, text, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be151ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:14.164556Z",
     "iopub.status.busy": "2025-06-05T03:19:14.164082Z",
     "iopub.status.idle": "2025-06-05T03:19:15.170021Z",
     "shell.execute_reply": "2025-06-05T03:19:15.168849Z",
     "shell.execute_reply.started": "2025-06-05T03:19:14.164522Z"
    },
    "id": "be151ce8",
    "outputId": "d70cb4d1-8ec3-414a-bb22-363fda7272be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/active-patcher/active_patcher/utils/annotations.py:67: ExperimentalWarning: The function from_arrays is experimental and maybe subject to change soon.\n",
      "  warnings.warn(f'The {subject} {func_or_class.__name__} is experimental '\n"
     ]
    }
   ],
   "source": [
    "from active_patcher import TransformersDataset\n",
    "\n",
    "num_classes = 2\n",
    "target_labels = np.arange(num_classes)\n",
    "\n",
    "train = TransformersDataset.from_arrays(raw_dataset['train']['diff'],\n",
    "                                        raw_dataset['train']['label'],\n",
    "                                        tokenizer,\n",
    "                                        max_length=512,\n",
    "                                        target_labels=target_labels)\n",
    "test = TransformersDataset.from_arrays(raw_dataset['test']['diff'],\n",
    "                                       raw_dataset['test']['label'],\n",
    "                                       tokenizer,\n",
    "                                       max_length=512,\n",
    "                                       target_labels=target_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ebf3d",
   "metadata": {
    "id": "017ebf3d"
   },
   "source": [
    "---\n",
    "\n",
    "<a name=\"nb1-part3-active-learning\"></a>\n",
    "## III. Setting up the Active Learner\n",
    "\n",
    "Now we constrauct a `PoolBasedActiveLearner` instance which requires a classifier factory, a query strategy, and the train dataset.\n",
    "\n",
    "To obtain a first model, we initialize the active learner by providing the true labels for 10 sentences. This corresponds to an initial labeling the real-world setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66774521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T03:19:15.171992Z",
     "iopub.status.busy": "2025-06-05T03:19:15.171322Z",
     "iopub.status.idle": "2025-06-05T03:19:42.591188Z",
     "shell.execute_reply": "2025-06-05T03:19:42.589886Z",
     "shell.execute_reply.started": "2025-06-05T03:19:15.171954Z"
    },
    "id": "66774521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_0-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_1-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_2-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_3-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_4-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_5-b0.pt.optimizer\n",
      "我去哪了 /root/active-patcher/tmp/tmpd8t055i9/model_6-b0.pt.optimizer\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:424] . unexpected pos 263155712 vs 263155600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/160: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m query_strategy \u001b[38;5;241m=\u001b[39m PredictionEntropy()\n\u001b[1;32m     29\u001b[0m active_learner \u001b[38;5;241m=\u001b[39m PoolBasedActiveLearner(clf_factory, query_strategy, train)\n\u001b[0;32m---> 30\u001b[0m indices_labeled \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_active_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_learner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m, in \u001b[0;36minitialize_active_learner\u001b[0;34m(active_learner, y_train)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_active_learner\u001b[39m(active_learner, y_train):\n\u001b[1;32m     14\u001b[0m     indices_initial \u001b[38;5;241m=\u001b[39m random_initialization_balanced(y_train, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mactive_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices_initial\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_initial\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/active_learner.py:154\u001b[0m, in \u001b[0;36mPoolBasedActiveLearner.initialize_data\u001b[0;34m(self, indices_initial, y_initial, indices_ignored, indices_validation, retrain)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices_ignored \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retrain:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_validation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/active_learner.py:393\u001b[0m, in \u001b[0;36mPoolBasedActiveLearner._retrain\u001b[0;34m(self, indices_validation)\u001b[0m\n\u001b[1;32m    390\u001b[0m dataset\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices_labeled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/transformers/classifiers/classification.py:378\u001b[0m, in \u001b[0;36mTransformerBasedClassification.fit\u001b[0;34m(self, train_set, validation_set, weights, early_stopping, model_selection, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_class_weights(sub_train)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_default_criterion(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weights_,\n\u001b[1;32m    376\u001b[0m                                              use_sample_weights\u001b[38;5;241m=\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_train_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_scheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/transformers/classifiers/classification.py:401\u001b[0m, in \u001b[0;36mTransformerBasedClassification._fit_main\u001b[0;34m(self, sub_train, sub_valid, weights, early_stopping, model_selection, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mget_tmp_dir_base()) \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_model_selection(optimizer, model_selection)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/transformers/classifiers/classification.py:432\u001b[0m, in \u001b[0;36mTransformerBasedClassification._train\u001b[0;34m(self, sub_train, sub_valid, weights, early_stopping, model_selection, optimizer, scheduler, tmp_dir)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop:\n\u001b[1;32m    430\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m--> 432\u001b[0m     train_acc, train_loss, valid_acc, valid_loss, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43msub_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43msub_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mmodel_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     timedelta \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch(epoch, timedelta, sub_train, sub_valid, train_acc, train_loss,\n\u001b[1;32m    445\u001b[0m                     valid_acc, valid_loss)\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/transformers/classifiers/classification.py:468\u001b[0m, in \u001b[0;36mTransformerBasedClassification._train_loop_epoch\u001b[0;34m(self, num_epoch, sub_train, sub_valid, weights, early_stopping, model_selection, optimizer, scheduler, tmp_dir)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     validate_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m train_loss, train_acc, valid_loss, valid_acc, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop_process_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_acc, train_loss, valid_acc, valid_loss, stop\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/transformers/classifiers/classification.py:535\u001b[0m, in \u001b[0;36mTransformerBasedClassification._train_loop_process_batches\u001b[0;34m(self, num_epoch, sub_train_, sub_valid_, weights, early_stopping, model_selection, optimizer, scheduler, tmp_dir, validate_every)\u001b[0m\n\u001b[1;32m    528\u001b[0m measured_values \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: train_acc,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_loss,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_acc\n\u001b[1;32m    533\u001b[0m }\n\u001b[1;32m    534\u001b[0m stop \u001b[38;5;241m=\u001b[39m early_stopping\u001b[38;5;241m.\u001b[39mcheck_early_stop(num_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, measured_values)\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-b0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtrain_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, train_acc, valid_loss, valid_acc, stop\n",
      "File \u001b[0;32m~/active-patcher/active_patcher/integrations/pytorch/classifiers/base.py:48\u001b[0m, in \u001b[0;36mPytorchModelSelectionMixin._save_model\u001b[0;34m(self, optimizer, model_selection, model_id, train_acc, train_loss, valid_acc, valid_loss, stop, tmp_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m measured_values \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: train_acc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_loss,\n\u001b[1;32m     46\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_acc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_loss}\n\u001b[1;32m     47\u001b[0m model_path \u001b[38;5;241m=\u001b[39m Path(tmp_dir)\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m optimizer_path \u001b[38;5;241m=\u001b[39m model_path\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt.optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我去哪了\u001b[39m\u001b[38;5;124m\"\u001b[39m,optimizer_path)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 263155712 vs 263155600"
     ]
    }
   ],
   "source": [
    "from active_patcher import (\n",
    "    PoolBasedActiveLearner,\n",
    "    PredictionEntropy,\n",
    "    TransformerBasedClassificationFactory,\n",
    "    TransformerModelArguments,\n",
    "    random_initialization_balanced,\n",
    "    RandomSampling\n",
    ")\n",
    "\n",
    "\n",
    "# simulates an initial labeling to warm-start the active learning process\n",
    "def initialize_active_learner(active_learner, y_train):\n",
    "\n",
    "    indices_initial = random_initialization_balanced(y_train, n_samples=20)\n",
    "    active_learner.initialize_data(indices_initial, y_train[indices_initial])\n",
    "\n",
    "    return indices_initial\n",
    "\n",
    "\n",
    "transformer_model = TransformerModelArguments(transformer_model_name)\n",
    "clf_factory = TransformerBasedClassificationFactory(transformer_model,\n",
    "                                                    num_classes,\n",
    "                                                    kwargs=dict({'device': 'cuda',\n",
    "                                                                 'mini_batch_size': 8,\n",
    "                                                                 'class_weight': 'balanced'\n",
    "                                                                }))\n",
    "# query_strategy = RandomSampling()\n",
    "query_strategy = PredictionEntropy()\n",
    "active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, train)\n",
    "indices_labeled = initialize_active_learner(active_learner, train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8888591",
   "metadata": {
    "id": "e8888591"
   },
   "source": [
    "### Active Learning Loop\n",
    "\n",
    "The main active learning loop queries the unlabeled pool and thereby decides which documents are labeled next.\n",
    "We then provide the labels for those documents and the active learner retrains the model.\n",
    "After each query, we evaluate the current model against the test set and save the result.\n",
    "\n",
    "\n",
    "Note: This is active learning as it is done in a scientific simulation. In reality, the label feedback would have been given by human annotators, and moreover, we would not be able to measure the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd866c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.592544Z",
     "iopub.status.idle": "2025-06-05T03:19:42.593172Z",
     "shell.execute_reply": "2025-06-05T03:19:42.592968Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.592947Z"
    },
    "id": "aacd866c",
    "outputId": "43d7fc0b-6d24-44f4-ebd0-c9eceff1f3b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "num_queries = 10\n",
    "\n",
    "\n",
    "def evaluate(active_learner, train, test):\n",
    "    y_pred = active_learner.classifier.predict(train)\n",
    "    y_pred_test = active_learner.classifier.predict(test)\n",
    "\n",
    "    test_acc = accuracy_score(y_pred_test, test.y)\n",
    "\n",
    "    print('Train accuracy: {:.2f}'.format(accuracy_score(y_pred, train.y)))\n",
    "    print('Test accuracy: {:.2f}'.format(test_acc))\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "results = []\n",
    "results.append(evaluate(active_learner, train[indices_labeled], test))\n",
    "\n",
    "\n",
    "for i in range(num_queries):\n",
    "    # ...where each iteration consists of labelling 20 samples\n",
    "    indices_queried = active_learner.query(num_samples=20)\n",
    "\n",
    "    # Simulate user interaction here. Replace this for real-world usage.\n",
    "    y = train.y[indices_queried]\n",
    "\n",
    "    # Return the labels for the current query to the active learner.\n",
    "    active_learner.update(y)\n",
    "\n",
    "    indices_labeled = np.concatenate([indices_queried, indices_labeled])\n",
    "\n",
    "    print('---------------')\n",
    "    print(f'Iteration #{i} ({len(indices_labeled)} samples)')\n",
    "    results.append(evaluate(active_learner, train[indices_labeled], test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb9a63",
   "metadata": {
    "id": "5eeb9a63"
   },
   "source": [
    "----\n",
    "\n",
    "<a id=\"nb1-part4-plotting\"></a>\n",
    "## IV. Plotting the Results\n",
    "\n",
    "Using the previously saved results we can plot a [learning curve](https://en.wikipedia.org/wiki/Learning_curve_(machine_learning)) to visualize the resulting accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2e186-d355-4c77-a5ae-8046676708f9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.594990Z",
     "iopub.status.idle": "2025-06-05T03:19:42.595409Z",
     "shell.execute_reply": "2025-06-05T03:19:42.595214Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.595195Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c5231-07a7-4370-96c9-ef85c8b485ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.596472Z",
     "iopub.status.idle": "2025-06-05T03:19:42.596860Z",
     "shell.execute_reply": "2025-06-05T03:19:42.596679Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.596660Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "# ax = plt.axes()\n",
    "\n",
    "data = np.stack((np.arange(num_queries + 1), np.array(results)), axis=1)\n",
    "# data = np.column_stack((np.arange(num_queries + 1), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1211fb6-4c08-49cd-890a-399e511d07c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.598558Z",
     "iopub.status.idle": "2025-06-05T03:19:42.598947Z",
     "shell.execute_reply": "2025-06-05T03:19:42.598764Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.598745Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcab05-402b-4bae-a82c-e6e975f4d2ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.600361Z",
     "iopub.status.idle": "2025-06-05T03:19:42.600750Z",
     "shell.execute_reply": "2025-06-05T03:19:42.600567Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.600548Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('random_strategy.npy',data)#如果文件路径末尾没有扩展名.npy，该扩展名会被自动加上。\n",
    "# res =  np.load('random_strategy.npy')\n",
    "# np.save('prediction_entropy.npy',data)#如果文件路径末尾没有扩展名.npy，该扩展名会被自动加上。\n",
    "res =  np.load('prediction_entropy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646df43-d8fd-4a52-8f53-9cfa779b0437",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.602113Z",
     "iopub.status.idle": "2025-06-05T03:19:42.602533Z",
     "shell.execute_reply": "2025-06-05T03:19:42.602337Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.602318Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c1d13",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T03:19:42.604119Z",
     "iopub.status.idle": "2025-06-05T03:19:42.604549Z",
     "shell.execute_reply": "2025-06-05T03:19:42.604347Z",
     "shell.execute_reply.started": "2025-06-05T03:19:42.604327Z"
    },
    "id": "278c1d13",
    "outputId": "6d518c20-fc55-4746-a8c7-b74b315ab13f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_queries = 10\n",
    "# results = [0.81, 0.83, 0.85, 0.86, 0.87, 0.88, 0.885, 0.89, 0.892, 0.895, 0.9]\n",
    "\n",
    "# data = np.column_stack((np.arange(num_queries + 1), results))\n",
    "\n",
    "sns.lineplot(x=res[:, 0], y=res[:, 1])\n",
    "plt.xlabel('number of queries', labelpad=15)\n",
    "plt.ylabel('test accuracy', labelpad=25)\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c6d7c-af22-4030-ad1f-c356071fe67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
